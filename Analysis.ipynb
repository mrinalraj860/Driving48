{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535a1829-9961-4846-af92-9ea4ce490f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Head:\n",
      "            vid_name  label  start_frame  end_frame\n",
      "0  -mmq0PT-u8k_00155      0            0         48\n",
      "1  -mmq0PT-u8k_00156      0            0         70\n",
      "2  -mmq0PT-u8k_00157      0            0         90\n",
      "3  3qq031609lA_00002      0            0        123\n",
      "4  3qq031609lA_00004      0            0        102\n",
      "\n",
      "Test Data Head:\n",
      "            vid_name  label  start_frame  end_frame\n",
      "0  8qRmKunCjtY_00016      0            0         78\n",
      "1  CVAfPfVFulQ_00038      0            0        100\n",
      "2  CVAfPfVFulQ_00040      0            0         79\n",
      "3  CVAfPfVFulQ_00048      0            0         76\n",
      "4  CVAfPfVFulQ_00049      0            0         83\n",
      "\n",
      "Unique Classes in Train: 47\n",
      "Unique Classes in Test: 47\n",
      "\n",
      "Train Class Distribution:\n",
      "label\n",
      "26    1053\n",
      "35     992\n",
      "7      901\n",
      "46     816\n",
      "21     689\n",
      "31     683\n",
      "19     604\n",
      "15     591\n",
      "34     571\n",
      "33     568\n",
      "45     559\n",
      "44     518\n",
      "24     484\n",
      "5      467\n",
      "8      424\n",
      "12     421\n",
      "43     406\n",
      "22     355\n",
      "17     349\n",
      "36     346\n",
      "28     326\n",
      "3      259\n",
      "27     250\n",
      "29     231\n",
      "0      222\n",
      "9      212\n",
      "41     160\n",
      "6      160\n",
      "20     148\n",
      "11     144\n",
      "42     130\n",
      "1      109\n",
      "14     102\n",
      "38      91\n",
      "10      74\n",
      "37      69\n",
      "18      68\n",
      "32      61\n",
      "23      57\n",
      "2       49\n",
      "40      48\n",
      "16      48\n",
      "25      46\n",
      "39      45\n",
      "13      44\n",
      "47      44\n",
      "4       33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Class Distribution:\n",
      "label\n",
      "46    163\n",
      "15    133\n",
      "19    117\n",
      "34     99\n",
      "35     95\n",
      "31     88\n",
      "36     81\n",
      "24     80\n",
      "0      73\n",
      "26     69\n",
      "44     67\n",
      "7      63\n",
      "45     57\n",
      "8      54\n",
      "21     52\n",
      "22     52\n",
      "28     51\n",
      "1      47\n",
      "32     43\n",
      "5      41\n",
      "16     39\n",
      "27     39\n",
      "33     39\n",
      "47     32\n",
      "20     31\n",
      "3      31\n",
      "12     28\n",
      "4      21\n",
      "6      21\n",
      "17     21\n",
      "29     20\n",
      "11     17\n",
      "25     16\n",
      "10     15\n",
      "18     14\n",
      "13     12\n",
      "41     10\n",
      "43      9\n",
      "23      7\n",
      "39      5\n",
      "37      4\n",
      "42      3\n",
      "2       3\n",
      "40      2\n",
      "38      2\n",
      "9       2\n",
      "14      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total video files in rgb/: 18404\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "base_path = '.'  # Replace with your actual path\n",
    "rgb_path = os.path.join(base_path, 'rgb')\n",
    "train_json = os.path.join(base_path, 'Diving48_V2_train.json')\n",
    "test_json = os.path.join(base_path, 'Diving48_V2_test.json')\n",
    "vocab_json = os.path.join(base_path, 'Diving48_vocab.json')\n",
    "\n",
    "# Load JSONs\n",
    "with open(train_json, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(test_json, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "with open(vocab_json, 'r') as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame for easy handling\n",
    "df_train = pd.DataFrame(train_data)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "# Show head\n",
    "print(\"Train Data Head:\")\n",
    "print(df_train.head())\n",
    "\n",
    "print(\"\\nTest Data Head:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# Count unique classes\n",
    "train_classes = df_train['label'].unique()\n",
    "test_classes = df_test['label'].unique()\n",
    "print(f\"\\nUnique Classes in Train: {len(train_classes)}\")\n",
    "print(f\"Unique Classes in Test: {len(test_classes)}\")\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\nTrain Class Distribution:\")\n",
    "print(df_train['label'].value_counts())\n",
    "\n",
    "print(\"\\nTest Class Distribution:\")\n",
    "print(df_test['label'].value_counts())\n",
    "\n",
    "# Check total MP4 files in RGB folder\n",
    "mp4_files = [f for f in os.listdir(rgb_path) if f.endswith('.mp4')]\n",
    "print(f\"\\nTotal video files in rgb/: {len(mp4_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7425254-9bcb-4eb3-9aed-5cbb54adbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def read_video_and_detect_yolo(video_path, start_frame=0, end_frame=None, model_path=\"yolo11x.pt\"):\n",
    "    \"\"\"\n",
    "    Reads video frames and runs YOLOv8 on the first frame.\n",
    "    Returns frames and YOLO detections from the first frame.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    current_frame = 0\n",
    "\n",
    "    # Validate video\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    # Load YOLOv8 model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if current_frame >= start_frame:\n",
    "            if end_frame is not None and current_frame > end_frame:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        current_frame += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(\"No frames extracted from video\")\n",
    "\n",
    "    # Run YOLO only on first frame\n",
    "    first_frame = frames[0]\n",
    "    results = model.predict(source=first_frame, classes=None, conf=0.25, verbose=False)\n",
    "    yolo_boxes = []\n",
    "\n",
    "    if len(results) > 0:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "            conf = box.conf[0].item()\n",
    "            cls_id = int(box.cls[0].item())\n",
    "            yolo_boxes.append([x1, y1, x2, y2, conf, cls_id])\n",
    "\n",
    "    return frames, yolo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd49401-2dab-42f5-aae0-57ce4c0e54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames: 157\n",
      "Detections in first frame:\n",
      "[431.69757080078125, 9.231010437011719, 460.45721435546875, 69.33294677734375, 0.4667394757270813, 56]\n"
     ]
    }
   ],
   "source": [
    "video_path = \"/Users/mrinalraj/Downloads/WebDownload/Driving48/rgb/VNvb5oLOpLg_00000.mp4\"\n",
    "start, end = 0, 156  # from json\n",
    "\n",
    "frames, detections = read_video_and_detect_yolo(video_path, start, end)\n",
    "\n",
    "print(\"Total Frames:\", len(frames))\n",
    "print(\"Detections in first frame:\")\n",
    "for det in detections:\n",
    "    print(det)  # x1, y1, x2, y2, confidence, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b70a11-6ff5-406a-805f-aa3c6b474b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def read_video_detect_draw(video_path, start_frame=0, end_frame=None, model_path=\"yolov8x.pt\"):\n",
    "    \"\"\"\n",
    "    Reads video frames and runs YOLOv8 on the first frame.\n",
    "    Draws detections and displays the first frame with boxes.\n",
    "    Returns all frames and the detected boxes.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    current_frame = 0\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    # Load YOLOv8 model\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if current_frame >= start_frame:\n",
    "            if end_frame is not None and current_frame > end_frame:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        current_frame += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(\"No frames extracted\")\n",
    "\n",
    "    # Run YOLO on the first frame\n",
    "    first_frame = frames[0].copy()\n",
    "    results = model.predict(source=first_frame, classes=None, conf=0.1, verbose=False)\n",
    "    yolo_boxes = []\n",
    "\n",
    "    # Draw YOLO detections\n",
    "    if len(results) > 0:\n",
    "        for box in results[0].boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            conf = box.conf[0].item()\n",
    "            cls_id = int(box.cls[0].item())\n",
    "            yolo_boxes.append([x1, y1, x2, y2, conf, cls_id])\n",
    "\n",
    "            # Draw box\n",
    "            cv2.rectangle(first_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"Class {cls_id} ({conf:.2f})\"\n",
    "            cv2.putText(first_frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"YOLO Detection - First Frame\", first_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return frames, yolo_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a544cfdd-39be-4eea-8d70-1aff11bf4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO Detections:\n",
      "Box: [431, 8, 460, 68, 0.2939814627170563, 56]\n",
      "Box: [5, 0, 51, 43, 0.2411947250366211, 56]\n",
      "Box: [332, 102, 378, 343, 0.20497339963912964, 0]\n",
      "Box: [253, 2, 290, 63, 0.1445455402135849, 56]\n",
      "Box: [186, 4, 223, 68, 0.11279432475566864, 56]\n",
      "Box: [220, 5, 257, 70, 0.10830151289701462, 56]\n"
     ]
    }
   ],
   "source": [
    "start_frame = 0\n",
    "end_frame = 156\n",
    "\n",
    "frames, boxes = read_video_detect_draw(video_path, start_frame, end_frame, model_path=\"yolov8x.pt\")\n",
    "\n",
    "print(\"YOLO Detections:\")\n",
    "for b in boxes:\n",
    "    print(f\"Box: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a2b4ac-529e-4785-aab2-2a9882e7c422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0610ac1-9e8a-41a6-a074-b878b7e24a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
